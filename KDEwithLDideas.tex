\documentclass{amsart}
\usepackage{mathtools,upref,siunitx,upquote,fancyvrb,xspace,color}
\usepackage[hyphens]{url}
\usepackage[utf8]{inputenc}
\usepackage{esdiff}
\usepackage[capitalise]{cleveref}

\input{FJHDef.tex}


\usepackage{algpseudocode}
\usepackage{algorithm, algorithmicx}
\algnewcommand\algorithmicparam{\textbf{Parameters:}}
\algnewcommand\PARAM{\item[\algorithmicparam]}
\algnewcommand\algorithmicinput{\textbf{Input:}}
\algnewcommand\INPUT{\item[\algorithmicinput]}
\algnewcommand\RETURN{\State \textbf{Return }}

\newcommand{\hvarrho}{\widehat{\varrho}}
\newcommand{\KY}{K^y}
\newcommand{\tKY}{\widetilde{K}^y}
\newcommand{\KX}{K^{\vx}}
\newcommand{\tk}{\tilde{k}}



\begin{document}
\title{Kernel Density Estimation Using Low Discrepancy Sampling}
\author{Fred J. Hickernell}
\begin{abstract}This project is where all of the files and commands go that are needed elsewhere
\end{abstract}

\maketitle

Let $Y = f(\vX)$, where $\vX \sim \cu[0,1]^d$.  Low discrepancy sequences are used for computing  $\mu = \Ex(Y)$.  Can they be used for estimation of $\varrho$, the probability density function of $Y$?

Let $\nu$ be a probability mass or density function.  A generalized kernel density estimator (KDE), $\hvarrho(\cdot,\nu,k)$, can be defined as
\begin{equation}
	\label{eq:genkde}
\hvarrho(y,\nu,k) := \int_{-\infty}^{\infty} k(z,y) \, \nu(z) \, \dif z, \qquad y \in \reals,
\end{equation}
where we call the $k:\reals \times \reals \to \reals$ the \emph{density kernel}. Here, $k(\cdot,y)$ is a weight function used to estimate the density at $y$, so $k(\cdot,y)$ should typically be larger near $y$ than away from $y$.   Moreover, we assume that
\begin{equation}
	\label{eq:kintegral}
	\int_{-\infty}^{\infty} k(z,y) \, \dif z = 1 \qquad \forall y \in \reals.
\end{equation}
For \eqref{eq:genkde} to be a good estimator, the density $\nu$ should approximate $\varrho$ well.

Let $\varrho_{\vy}$ be the empirical probability mass function of a vector of samppled $Y$ values, $\vy = (y_1, \ldots, y_n)$.  Then a \emph{practical KDE} is
\begin{equation*}
\hvarrho(y,\varrho_{\vy},k) = \int_{-\infty}^{\infty} k(z,y) \, \varrho_{\vy}(z) \, \dif z = \frac 1n \sum_{i=1}^n k(y_i,y) \\
 = \frac 1n \sum_{i=1}^n k(f(\vx_i),y) .
\end{equation*}
Moreover, a \emph{smoothed density} can be defined as
\[
\hvarrho(y,\varrho,k) = \int_{-\infty}^{\infty} k(z,y) \, \varrho(z) \, \dif z = \int_{[0,1]^d} k(f(\vx),y) \,  \dif \vx.
\]

The absolute error of the practical KDE  can be bounded as the sum of two terms:
\begin{align*}
    \abs{\varrho(y) - \hvarrho(y,\varrho_{\vy},k)} & =
     \abs{\varrho(y) - \hvarrho(y,\varrho,k) + \hvarrho(y,\varrho,k) - \hvarrho(y,\varrho_{\vy},k)} \\
     & \le  \abs{\varrho(y) - \hvarrho(y,\varrho,k)} + \abs{\hvarrho(y,\varrho,k) - \hvarrho(y,\varrho_{\vy},k)}.
\end{align*}
The first term depends on the density kernel and measures how well the smoothed density estimates the true density.  The second term measures how well the practical KDE estimates the smoothed density.
We will analyze the two terms separately assuming that $\varrho$ and $k(f(\cdot),y)$ lie in reproducing kernel Hilbert spaces.

Let $\KY:\reals \times \reals \to \reals$ be a reproducing kernel for a Hilbert space containing $\varrho$.  Then an upper bound on the first term in the expression for the error can be bounded via the Cauchy-Schwarz inequality and the Riesz representation theorm:
\begin{align}
\label{eq:firstbd}
\abs{\varrho(y) - \hvarrho(y,\varrho,k)}
& = \abs{\varrho(y) - \int_{-\infty}^{\infty} k(z,y) \, \varrho(z) \, \dif z} \\
\nonumber
& = \abs{\ip[\KY]{\KY(\cdot,y) - \int_{-\infty}^{\infty} k(z,y) \, \KY(z,\cdot) \,  \dif z}{\varrho} } \\
\nonumber
& \le  \norm[\KY]{\KY(\cdot,y) - \int_{-\infty}^{\infty} k(z,y) \, \KY(z,\cdot) \, \dif z} \norm[\KY]{\varrho},
\end{align}
where the part of the error bound depending on density kernel can be rewritten in terms of integrals:
\begin{align}
\label{eq:kquality}
\MoveEqLeft{\norm[\KY]{\KY(\cdot,y) - \int_{-\infty}^{\infty} k(z,y) \, \KY(z,\cdot) \, \dif z}^2} \\ \nonumber
&=  \KY(y,y) - 2 \int_{-\infty}^{\infty} k(z,y) \, \KY(z,y) \, \dif z \\ \nonumber
& \qquad \qquad + \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}  k(z,y) \, \KY(z,t) \, k(t,y)\, \dif z \, \dif t.
\end{align}
\Cref{eq:firstbd} is an upper bound on the first term in the expression for the error that separates the part depending on the choice of the density kernel from the part depending on the probability density.

Let $\KX: [0,1]^d \times [0,1]^d\to \reals$ be a reproducing kernel for a Hilbert space containing $k(y,f(\cdot))$ for all $y \in \reals$ and all $f$ of interest. Then
\begin{align*}
\abs{\hvarrho(y,\varrho,k) - \hvarrho(y,\varrho_{\vy},k)}
& = \abs{\int_{-\infty}^{\infty} k(z,y) \, \varrho(z) \, \dif z -
\frac 1n \sum_{i=1}^n k(y_i,y)} \\
& = \abs{\int_{[0,1]^d} k(f(\vx),y) \, \dif \vx -
\frac 1n \sum_{i=1}^n k(f(\vx_i),y)} \\
& = \abs{\ip[\KY]{\int_{[0,1]^d} \KX(\cdot,\vx) \, \dif \vx -
\frac 1n \sum_{i=1}^n \KX(\cdot,\vx_i)}{k(f(\cdot),y) }} \\
& \le  \norm[\KX]{\int_{[0,1]^d} \KX(\cdot,\vx) \, \dif \vx -
\frac 1n \sum_{i=1}^n \KX(\cdot,\vx_i)} \norm[\KX]{k(f(\cdot),y) } ,
\end{align*}
where
\begin{align*}
\MoveEqLeft{\norm[\KX]{\int_{[0,1]^d} \KX(\cdot,\vx) \, \dif \vx -
\frac 1n \sum_{i=1}^n \KX(\cdot,\vx_i)}^2} \\
&=  \int_{[0,1]^d \times [0,1]^d} \KX(\vx,\vt) \, \dif \vx \, \dif \vt -
\frac 2n \sum_{i=1}^n \int_{[0,1]^d} \KX(\vx,\vx_i) \, \dif \vx \\
& \qquad \qquad + \frac 1{n^2} \sum_{i,j=1}^n  \KX(\vx_i,\vx_j) .
\end{align*}
This is an upper bound on the second term in the expression for the error that separates the part depending on the choice of the kernel evaluated at $(f(\cdot),y)$ from the part depending on the sample nodes.

\section{Isotropic Density Kernels}

Suppose that $k(z,y) = h^{-1}\tk((z-y)/h)$ where $h$ is a bandwidth, and $\KY(y,z) = \tKY(y-z)$.  Then the quantity measuring the quality of the density kernel in \eqref{eq:kquality} may be written as
\begin{align*}
\MoveEqLeft{\norm[\KY]{\KY(\cdot,y) - \int_{-\infty}^{\infty} k(z,y) \, \KY(z,\cdot) \, \dif z}^2} \\
&=  \tKY(0) -  \frac 2h \int_{-\infty}^{\infty} \tk((z-y)/h) \, \tKY(z-y) \, \dif z \\
& \qquad \qquad + \frac 1{h^2} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}  \tk((z-y)/h)  \, \tKY(z-t) \, \tk((t-y)/h) \, \dif z \, \dif t \\
&=   \tKY(0) - 2 \int_{-\infty}^{\infty} \tk(w) \, \tKY(hw) \, \dif w \\
& \qquad \qquad + \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}  \tk(w) \, \tKY(h(w-v)) \, \tk(v)\, \dif w \, \dif v
.
\end{align*}
via the variable transformations $w = (z-y)/h$ and $v = (t-y)/h$.

Let $\tKY(y) = \exp(-y^2/2)$ and $\tk(y) = \exp(-y^2/2)/\sqrt{2\pi}$.

\bibliographystyle{amsplain}
\bibliography{FJH23,FJHown23}

\end{document}